


多线程：7.8s  1702条数据
![img.png](img.png)
![img_3.png](img_3.png)


顺序执行： 67.6s  13104条数据
![img_4.png](img_4.png)

异步并发最终的数据数量少于预期值：
猜测：Python的列表非线程安全。并发会导致数据增加失败


`异步爬虫总是前三个请求 的数据为0`

这个问题的`根因是`：
1.未限制并发量
        使用信号量semaphore机制，限制并发请求为3。
~~~
    con_req = 3
    sem = asyncio.Semaphore(con_req)
    async with semaphore:
    html = await get_fume(client, cc)
~~~

2.未携带请求头的User-Agent到htppx库
~~~
    async with AsyncClient() as client:
        headers = { "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",}
        client.headers.update(headers)
        
~~~

怎么发现是并发量的问题？
讲每次请求的数据记录在日志文件中，发现前三次的请求必为空。而顺序请求都能在正常获得数据。
我推断除服务器那边是正常的收发数据，问题应该是代码写的不对
对比顺序请求，发现未加请求头。加了请求头后，还是少数据。
今天刚好看到书中利用信号量在限制并发量，我就往限制并发量方向考虑，结果这就是根因。





怎么用异步编程实现爬虫的？
我把抽象成一个模板写法：
第一步是定义一个不同函数,返回值是事件循环，该事件循环函数的参数是一个用async def 定义的协程函数
第二步是在这个协程函数中利用asyncio.gather函数驱动任务协程函数。任务协程函数就是总的爬虫任务分解成一个个独立的子任务函数，
比如说我们需要爬取100个不同的url的web页面，这是我们的总的爬虫任务，我们只需要写一个任务协程函数，形参就是url，这个传入url
的函数就是任务协程函数。
最后就是收集asyncio.gather函数的结果。

有些细节您有兴趣听吗?
1.对于顺序爬虫或者多线程常见是采用Requests库，但是requests库是同步库，所以异步编程需要异步库来实现，比如HTTPX库。

遇到的问题？
1.现象同一爬虫参数条件下异步并发获取到的数据比顺序爬虫少。
过程：记录，并分析了日志文件，个别几个请求结果返回的数据为空
原因：刚开始异步爬虫时没有限制并发量，使得请求几乎是同一时间向服务器发过去，导致服务器压力变大，返回的几个爬虫请求数据为空。
解决：我使用asyncio提供的信号量机制，初始化设置为3，将听异步上下文管理器包裹住网络请求函数，使得同一时刻最大的请求数量为3，问题解决


